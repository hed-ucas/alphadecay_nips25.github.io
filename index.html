<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="AlphaDecay: Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs">
  <meta name="keywords" content="AlphaDecay, Weight Decay, Large Language Models, LLM, Deep Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AlphaDecay: Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
<style>
.publication-title.sebra-style {
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    font-size:   40px;        
    font-weight: 400;      
    line-height: 1.1;
    color:       #000;
    text-transform: none;    
    letter-spacing: -0.2px;
}
</style>
  
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">







          
<!-- 机构 logo 栏（无浮动，轻美化） -->
<div class="institution-logos">
  <style>
    .institution-logos {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      align-items: center;
      gap: 1.2rem;
      padding: 1rem 1.5rem;
      margin: 1rem 0 2rem 0;
      background: #f5f5f7;          /* 浅灰背景 */
      border-radius: 12px;          /* 圆角卡片 */
      box-shadow: 0 2px 6px rgba(0,0,0,.05);
    }
    .institution-logos img {
      height: 48px;
      width: auto;
      object-fit: contain;
      background: #fff;             /* 白底防透图 */
      padding: 4px 8px;
      border: 2px solid #e0e0e0;    /* 细描边 */
      border-radius: 6px;
      transition: none;             /* 禁用任何浮动/放大 */
      cursor: default;
    }
    @media (max-width: 768px) {
      .institution-logos img {
        height: 40px;
      }
    }
  </style>

  <img src="./images/sz.png"     alt="SIAT">
  <img src="./images/pcl.png"    alt="PCL">
  <img src="./images/ucas.png"   alt="UCAS">
  <img src="./images/surrey.png" alt="UoS">
  <img src="./images/oxford.png" alt="Oxford">
  <img src="./images/SUAT.png"   alt="SUAT">
  <img src="./images/texas.png"  alt="UT Austin">
  <img src="./images/zhongshan.png" alt="SYSU">
</div>






          
          <h1 class="title publication-title sebra-style">
    AlphaDecay: Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs
</h1>
<style>

.agarshk-authors {
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    font-size: 18px;
    font-weight: 400;
    line-height: 1.35;
    color: #000;
}
.agarshk-authors .author-block {
    display: inline;
    margin-right: .25em;
}
.agarshk-authors a {
    color: #209CEE;
    text-decoration: none;
}
.agarshk-authors sup {
    font-size: .75em;
    vertical-align: super;
    margin-left: .1em;
    color: #000; 
}
</style>

<div class="agarshk-authors">
  <span class="author-block">
    <a href="https://github.com/hed-ucas">Di He</a><sup>1,2,3</sup>,
  </span>
  <span class="author-block">
    <a href="https://scholar.google.com/citations?user=_5Ir0soAAAAJ&hl=en">Songjun Tu</a><sup>2,3</sup>,
  </span>
  <span class="author-block">
    <a href="https://scholar.google.com/citations?hl=en&user=I783HxYAAAAJ&view_op=list_works&sortby=pubdate">Ajay Jaiswal</a><sup>4</sup>,
  </span>
  <span class="author-block">
    <a href="https://sites.google.com/site/mathshenli/home">Li Shen</a><sup>5</sup>,
  </span>
  <span class="author-block">
    <a href="https://yuangzh.github.io/">Ganzhao Yuan</a><sup>6</sup>,
  </span>
  <span class="author-block">
    <a href="https://scholar.google.com/citations?user=73IbXtsAAAAJ&hl=en">Shiwei Liu</a><sup>7</sup>,
  </span>
  <span class="author-block">
    <a href="https://luuyin.com/">Lu Yin</a><sup>8*</sup>
  </span>
</div>

<div class="publication-authors" style="margin-top: 0.8em;">
  <span class="author-block"><sup>1</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences,</span>
  <span class="author-block"><sup>2</sup>Peng Cheng Laboratory,</span>
  <span class="author-block"><sup>3</sup>University of Chinese Academy of Sciences,</span>
  <span class="author-block"><sup>4</sup>University of Texas at Austin,</span>
  <span class="author-block"><sup>5</sup>Shenzhen Campus of Sun Yat-sen University,</span>
  <span class="author-block"><sup>6</sup>Shenzhen University of Advanced Technology， </span>
  <span class="author-block"><sup>7</sup>University of Oxford， </span>
  <span class="author-block"><sup>8</sup>University of Surrey， </span>
</div>

          <div class="is-size-5 has-text-weight-bold" style="margin-top:-1.5rem;">
            NeurIPS 2025
          </div>

          <div class="is-size-5.5 has-text-weight-normal">
            *Corresponding author
          </div>
          
          <div class="column has-text-centered" style="margin-top:-0.5rem;">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2506.14562"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hed-ucas/AlphaDecay"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Alphadecay Overview. -->
<section class="section" style="margin-top:-3.5rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified" style="margin-top:0;">
            <p style="margin-bottom:0.4rem;">
              <strong>AlphaDecay</strong> is a plug-and-play method that boosts training efficacy for diverse optimizers by dynamically tuning <em>module-wise</em> weight-decay coefficients according to the spectral-feature discrepancies observed in LLMs, yielding better perplexity and downstream generalization.
            </p>
            <p style="margin-bottom:0.4rem;">
              <span class="icon has-text-info"><i class="fas fa-check-circle"></i></span>
              <strong>Zero Extra Tuning Cost:</strong> After the global weight-decay value is fixed, AlphaDecay is applied instantly—no additional search is required.
            </p>
            <p style="margin-bottom:0.4rem;">
              <span class="icon has-text-success"><i class="fas fa-cogs"></i></span>
              <strong>Optimizer Agnostic Mode:</strong> One-click integration with Adam, AdamW and more; no per-optimizer code changes.
            </p>
            <p style="margin-bottom:0;">
              <span class="icon has-text-warning"><i class="fas fa-tasks"></i></span>
              <strong>Task Versatile Support:</strong> Demonstrated gains on LLM pre-training, fine-tuning, vision transformers, and large-scale image classification.
            </p>
          </div>
      </div>
    </div>
  </div>
</section>

<!-- Module Spectral Analysis -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            <span class="icon has-text-primary"><i class="fas fa-wave-square"></i></span>
            <strong>Distinct Spectra:</strong> Attention layers exhibit <em>heavier-tailed</em> spectra, whereas MLP layers show <em>lighter-tailed</em> characteristics.
          </p>
          <div class="has-text-centered">
            <img src="./images/module_spectral.png" alt="Module Spectral" style="width: 80%; max-width: 900px; margin: 20px auto; display: block;">
          </div>

          <p>
            <span class="icon has-text-info"><i class="fas fa-chart-line"></i></span>
            <strong>PL_Alpha-Hill Guided:</strong> AlphaDecay assigns larger weight decay to modules with higher PL_Alpha_Hill values, and smaller decay to those with lower values.
          </p>
          <div class="has-text-centered">
            <img src="./images/more_stru.png" alt="More Structure" style="width: 80%; max-width: 600px; margin: 20px auto; display: block;">
          </div>

          <p>
            <span class="icon has-text-success"><i class="fas fa-balance-scale"></i></span>
            <strong>Spectrum Balanced:</strong> By equalizing module-wise spectra, AlphaDecay consistently improves performance over existing optimizers.
          </p>
          <div class="has-text-centered">
            <img src="./images/diff_WD.png" alt="Different Weight Decay" style="width: 80%; max-width: 600px; margin: 20px auto; display: block;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  

<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experimental Results</h2>
    
    <!-- Main Results -->
    <div class="content">
      <h3 class="title is-4">Main Results: LLaMA Pre-training on C4 Dataset</h3>
      <p class="has-text-justified">
        Comparison with various weight decay scheduling strategies using Adam optimizer on pre-training various sizes of LLaMa models (60M, 135M, 350M, 1B) on C4 dataset. Validation perplexity (↓) is reported. All baselines are carefully tuned. AlphaDecay consistently outperforms uniform decay, AWD, and AdaDecay across all model sizes and weight decay values.
      </p>
      <div class="has-text-centered">
        <img src="./images/main_result.png" alt="Main Results" style="width: 80%; max-width: 900px; margin: 20px auto; display: block;">
      </div>
    </div>

    <!-- Zero-shot Evaluation -->
    <div class="content" style="margin-top: 50px;">
      <h3 class="title is-4">Zero-shot Evaluation on Downstream Tasks</h3>
      <p class="has-text-justified">
        Zero-shot performance comparison on various downstream tasks including ARC-c, ARC-e, PIQA, Hellaswag, OBQA, Winogrande, and BOOLQ. AlphaDecay demonstrates superior generalization capability, outperforming Uniform, AdaDecay, and AWD methods.
      </p>
      <div class="has-text-centered">
        <img src="./images/zeros-shot.png" alt="Zero-shot Results" style="width: 80%; max-width: 600px; margin: 20px auto; display: block;">
      </div>
    </div>

        <!-- Zero-shot Evaluation -->
    <div class="content" style="margin-top: 50px;">
      <h3 class="title is-4">More model structures and datasets</h3>
      <p class="has-text-justified">
        Comparison of AlphaDecay with baseline methods on GPT-nano/C4 and ViT-tiny/ImageNet-1K. AlphaDecay achieves the best performance across different architectures and datasets.
      </p>
      <div class="has-text-centered">
        <img src="./images/method.png" alt="Zero-shot Results" style="width: 80%; max-width: 600px; margin: 20px auto; display: block;">
      </div>
    </div>
    
  </div>
</section>

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{he2025alphadecay,
  title={AlphaDecay: Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs},
  author={He, Di and Jaiswal, Ajay and Tu, Songjun and Shen, Li and Yuan, Ganzhao and Liu, Shiwei and Yin, Lu},
  journal={arXiv preprint arXiv:2506.14562},
  year={2025}
}</code></pre>
  </div>
</section>

<!-- Acknowledgements -->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      This repository is built upon the <a href="https://github.com/jiaweizzhao/GaLore">Galore</a> and <a href="https://github.com/jiaweizzhao/GaLore">ConvNeXt</a> repositories. Thanks for their great work!
    </p>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://export.arxiv.org/abs/2506.14562">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/hed-ucas/alphadecay_nips25.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
